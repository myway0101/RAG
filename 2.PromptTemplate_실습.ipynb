{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["반복적으로 사용되는 프롬프트를 템플릿으로 만들자"],"metadata":{"id":"EoCWg6qhs7L1"}},{"cell_type":"code","source":["# -q 플래그는 설치 중에 출력되는 메시지를 최소화합니다.\n","# openai: OpenAI API와 상호작용하기 위한 라이브러리\n","# langchain: 다양한 언어 모델과의 연결 및 데이터 파이프라인을 구축하기 위한 라이브러리\n","# langchain-openai: LangChain과 OpenAI API를 통합하는 기능을 제공하는 추가 라이브러리\n","!pip install -q openai langchain langchain-openai"],"metadata":{"id":"EBFyoFPb-_7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740111110269,"user_tz":-540,"elapsed":5356,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}},"outputId":"de4d8752-e5d3-4787-89ef-9ce488cedf85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q langchain_community # 다양한 추가 기능 및 도구를 제공하여 LangChain의 활용도를 높입니다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FE7BpOlF6fDP","executionInfo":{"status":"ok","timestamp":1740111132034,"user_tz":-540,"elapsed":21766,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}},"outputId":"95de5ae1-494e-4def-d38a-28a95bcafc75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qhh9fyI8-d9v"},"outputs":[],"source":["#API KEY 저장을 위한 os 라이브러리 호출\n","import os\n","#채팅 LLM 로드를 위한 라이브러리 호출\n","from langchain.chat_models import ChatOpenAI"]},{"cell_type":"code","source":["#OPENAI API키 저장\n","os.environ[\"OPENAI_API_KEY\"] = ## API Key ##"],"metadata":{"id":"9F6f494n-IWA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["-------"],"metadata":{"id":"DczHm9qI994V"}},{"cell_type":"markdown","source":["#### 모델 설정하기"],"metadata":{"id":"THkva8fB-C0f"}},{"cell_type":"code","source":["chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", max_tokens = 512)"],"metadata":{"id":"lRrUTsIb8GOb","executionInfo":{"status":"ok","timestamp":1740112352867,"user_tz":-540,"elapsed":1329,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"08c1cde1-04ea-4791-e8c1-a970ff32852e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-53add3f9e9ca>:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n","  chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", max_tokens = 512)\n"]}]},{"cell_type":"markdown","source":["#### (1) 프롬프트 템플릿 맛보기"],"metadata":{"id":"QhCfB_lQ-uqx"}},{"cell_type":"markdown","source":["프롬프트 템플릿은 크게 2가지가 존재합니다.\n","1. Prompt Template\n","2. Chat Prompt Template\n","\n","1번 Prompt Template은 일반적인 프롬프트 템플릿을 생성할때 활용합니다.\n","\n","2번 Chat Prompt Template은 채팅 LLM에 프롬프트를 전달하는 데에 활용할 수 있는 특화 프롬프트 템플릿입니다.\n","\n"],"metadata":{"id":"LrfEmGR5Ctbq"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate, ChatPromptTemplate\n","\n","#프롬프트 템플릿을 통해 매개변수 삽입 가능한 문자열로 변환\n","string_prompt = PromptTemplate.from_template(\"tell me a joke about {subject}\")  # subject를 중괄호로 넣어서 가변적인 매개변수로 설정\n","\n","#매개변수 삽입한 결과를 string_prompt_value에 할당\n","string_prompt_value = string_prompt.format_prompt(subject=\"soccer\")  # subject에 어떤것을 넣을지 설정\n","\n","#채팅LLM이 아닌 LLM과 대화할 때 필요한 프롬프트 = string prompt\n","string_prompt_value"],"metadata":{"id":"-bX3Wvsy-tyv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de3a848e-e4e4-4005-c475-31e025145301","executionInfo":{"status":"ok","timestamp":1740112412927,"user_tz":-540,"elapsed":19,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StringPromptValue(text='tell me a joke about soccer')"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#to_string() 함수를 통해 prompt template으로 생성한 문장 raw_text 반환 가능\n","print(string_prompt_value.to_string())"],"metadata":{"id":"6F3GCMX7-7j8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d82b0bda-355a-4c1f-8903-986ec4ff69ee","executionInfo":{"status":"ok","timestamp":1740112420060,"user_tz":-540,"elapsed":14,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tell me a joke about soccer\n"]}]},{"cell_type":"code","source":["chat_prompt = ChatPromptTemplate.from_template(\"tell me a joke about {subject}\") # 이것도 위와 같은 기능\n","chat_prompt_value = chat_prompt.format_prompt(subject=\"soccer\")\n","chat_prompt_value"],"metadata":{"id":"vylmSAk2_dfk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"04d04df3-46a6-494e-8272-a43879fbe6a7","executionInfo":{"status":"ok","timestamp":1740112956148,"user_tz":-540,"elapsed":16,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptValue(messages=[HumanMessage(content='tell me a joke about soccer', additional_kwargs={}, response_metadata={})])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["chat_prompt_value.to_string()"],"metadata":{"id":"47q4Uy2y_bM8","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"a4bc1e89-1ca1-4b74-b6b1-cbcb0f6e4686","executionInfo":{"status":"ok","timestamp":1740112958820,"user_tz":-540,"elapsed":11,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Human: tell me a joke about soccer'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["answer = chatgpt(chat_prompt_value.to_messages())\n","print(answer.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHnSpiWey_kT","executionInfo":{"status":"ok","timestamp":1740113026611,"user_tz":-540,"elapsed":886,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}},"outputId":"1c9f0ba1-3163-47fb-88f8-e5382cc5ccea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Why was the soccer field so hot? Because all the fans left!\n"]}]},{"cell_type":"markdown","source":["#### (2) 프롬프트 템플릿 활용해보기"],"metadata":{"id":"jVF-pxeUE4JI"}},{"cell_type":"markdown","source":["반복적인 프롬프트를 삽입해야하는 경우, Prompt Template를 통해 간편하게 LLM을 활용할 수 있습니다."],"metadata":{"id":"RIoNBQ_HFNlm"}},{"cell_type":"markdown","source":["- 프롬프트 템플릿을 활용하여 대화해보기"],"metadata":{"id":"25dmtYfJajHS"}},{"cell_type":"code","source":["from langchain.prompts.prompt import PromptTemplate\n","# 템플릿 정의: 요리사 역할을 부여하고, 사용 가능한 재료를 입력받아 요리를 추천하고 레시피를 제시하는 프롬프트\n","template = \"\"\"\n","너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 추천하고, 그 요리의 레시피를 제시해줘.\n","내가 가진 재료는 아래와 같아.\n","\n","<재료>\n","{재료}\n","\n","\"\"\"\n","# PromptTemplate 객체 생성: 템플릿과 입력 변수를 지정하여 프롬프트 템플릿을 만듭니다\n","prompt_template = PromptTemplate(\n","    input_variables = ['재료'],  # 리스트 형태로 사용 (여러개를 사용할 수 있음)\n","    template = template\n",")\n"],"metadata":{"id":"p1urKI18_bxI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(prompt_template.format(재료 = '양파, 계란, 사과, 빵')) # prompt_template의 format() 메서드를 사용하여 '재료' 변수에 '양파, 계란, 사과, 빵' 값을 할당하고, 최종 프롬프트를 생성하여 출력합니다."],"metadata":{"id":"lhBbXyEWGGE5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2cccfe6-1e9c-459a-eabd-7c25e4d5f430","executionInfo":{"status":"ok","timestamp":1740113243366,"user_tz":-540,"elapsed":6,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 추천하고, 그 요리의 레시피를 제시해줘.\n","내가 가진 재료는 아래와 같아.\n","\n","<재료>\n","양파, 계란, 사과, 빵\n","\n","\n"]}]},{"cell_type":"code","source":["from langchain.schema import HumanMessage # langchain 라이브러리에서 HumanMessage 클래스를 임포트합니다. HumanMessage는 LLM에게 전달할 메시지를 담는 객체입니다.\n","# HumanMessage 객체를 생성하여 LLM에게 전달할 메시지를 설정\n","answer = chatgpt(\n","    [HumanMessage(content=prompt_template.format(\n","        재료 = '양파, 계란, 사과, 빵'\n","    ))]\n",")\n","print(answer.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-N4Rpto8YvH","executionInfo":{"status":"ok","timestamp":1740113399369,"user_tz":-540,"elapsed":2772,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}},"outputId":"e304acda-dd55-4ba6-d3eb-6fdf405c1154"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["네, 제가 추천하는 요리는 \"양파 계란말이\" 입니다. \n","\n","<양파 계란말이 레시피>\n","1. 양파를 얇게 채썰어 준비합니다.\n","2. 계란 2개를 풀어 볼에 넣고 소금으로 간을 해줍니다.\n","3. 팬에 식용유를 두르고 양파를 볶다가 계란을 부어줍니다.\n","4. 계란이 익을 때쯤 양념을 해주고 섞어줍니다.\n","5. 부드럽게 익은 양파 계란말이를 빵과 함께 내어 드세요.\n","\n","재료로 가지고 있는 양파와 계란으로 간단하게 만들 수 있는 요리이니 맛있게 즐기시길 바랍니다. 만약 추가적인 요리나 레시피가 필요하시다면 말씀해주세요!\n"]}]},{"cell_type":"markdown","source":["##  ChatGPT와 프롬프트 템플릿을 활용하여 대화해보기"],"metadata":{"id":"Ea5k-T2KacpR"}},{"cell_type":"code","source":["# chatgpt의 프롬프트 템플릿을 더 잘 활용하기 위해서는 ChatPromptTemplate을 사용\n","from langchain.prompts import (\n","    ChatPromptTemplate,\n","    PromptTemplate,\n","    SystemMessagePromptTemplate,\n","    AIMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.schema import (\n","    AIMessage,\n","    HumanMessage,\n","    SystemMessage\n",")"],"metadata":{"id":"9yRP_2-aR9yr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ChatGPT 모델을 로드합니다.\n","chatgpt = ChatOpenAI(temperature=0)\n","\n","template = \"\"\"\n","너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 추천하고, 그 요리의 레시피를 제시해줘.\n","내가 가진 재료는 아래와 같아.\n","\n","<재료>\n","{재료}\n","\n","\"\"\"\n","\n","#ChatGPT에게 역할을 부여합니다.(위에서 정의한 Template 사용)\n","system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n","\n","#사용자가 입력할 매개변수 template을 선언합니다.\n","human_template = \"{재료}\"\n","human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n","\n","#ChatPromptTemplate에 system message와 human message 템플릿을 삽입합니다.\n","chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n","\n","#ChatGPT API에 ChatPromptTemplate을 입력할 때, human message의 매개변수인 '재료'를 할당하여 전달합니다.\n","#이와 같은 방식을 통해 ChatGPT는 ChatPromptTemplate의 구성요소인 system message와 human message를 전달받아, 대답 생성에 활용합니다.\n","answer = chatgpt(chat_prompt.format_prompt(재료=\"양파, 계란, 사과, 빵\").to_messages())\n","print(answer.content)"],"metadata":{"id":"7jgLtLMPHKI2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"60b52cc3-cf4f-4a18-93f2-3af24366dd4c","executionInfo":{"status":"ok","timestamp":1740113602367,"user_tz":-540,"elapsed":4463,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["제가 추천하는 요리는 \"양파 계란 토스트\"입니다. 이 요리는 간단하면서도 맛있는 아침 식사나 간식으로 딱 좋아요. 준비물과 레시피는 아래와 같습니다.\n","\n","<양파 계란 토스트>\n","\n","<재료>\n","- 빵 4조각\n","- 계란 2개\n","- 양파 1개\n","- 소금\n","- 후추\n","- 식용유\n","\n","<레시피>\n","1. 양파를 얇게 슬라이스해줍니다.\n","2. 팬에 식용유를 두르고 양파를 볶아 투명해질 때까지 볶아줍니다.\n","3. 볶은 양파를 접시에 옮겨놓고 팬을 세척하지 않습니다.\n","4. 계란 2개에 소금과 후추를 넣고 푹푹 섞어줍니다.\n","5. 팬에 계란을 부어 반숙 계란을 만들어줍니다.\n","6. 계란이 익으면 빵을 넣어 한쪽 면이 바삭해질 때까지 구워줍니다.\n","7. 빵을 뒤집어 반대편도 구워줍니다.\n","8. 빵 한 쪽에 양파를 얹고, 그 위에 계란을 올려줍니다.\n","9. 다른 빵으로 덮어주고 완성합니다.\n","\n","맛있는 양파 계란 토스트가 완성되었어요. 맛있게 드세요!\n"]}]},{"cell_type":"markdown","source":["###(3) Few-shot 예제를 통한 프롬프트 템플릿"],"metadata":{"id":"LSEhdhkRazTL"}},{"cell_type":"markdown","source":["Few-shot이란, 딥러닝 모델이 결과물을 출력할 때 예시 결과물을 제시함으로써 원하는 결과물로 유도하는 방법론입니다.\n","\n","LLM 역시, Few-shot 예제를 제공하면 예제와 유사한 형태의 결과물을 출력합니다.\n","\n","내가 원하는 결과물의 형태가 특수하거나, 구조화된 답변을 원할 경우, 결과물의 예시를 수 개 제시함으로써 결과물의 품질을 향상시킬 수 있습니다."],"metadata":{"id":"oXkGkd_Xa5o6"}},{"cell_type":"code","source":["from langchain.prompts.few_shot import FewShotPromptTemplate\n","from langchain.prompts.prompt import PromptTemplate\n","\n","examples = [\n","  {\n","    \"question\": \"호날두로 삼행시 만들어줘\",\n","    \"answer\":\n","\"\"\"\n","호: 호날두는 축구장에서\n","날: 날라다니며\n","두: 두발로 골을 넣는다\n","\"\"\"\n","  },\n","\n","  {\n","    \"question\": \"김민수로 삼행시 만들어줘\",\n","    \"answer\":\n","\"\"\"\n","김: 김치는 맛있다\n","민: 민달팽이도 좋아하는 김치!\n","수: 수억을 줘도 김치는 내꺼!\n","\"\"\"\n","  }\n","]"],"metadata":{"id":"P71OBMpBVPY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n","\n","print(example_prompt.format(**examples[0])) # **는 Python에서 키워드 인수 언팩킹\n","                                            # 이를 통해 딕셔너리의 키-값 쌍을 함수에 인수로 전달\n","                                            # examples[0]의 내용을 question과 answer라는 변수로 각각 전달"],"metadata":{"id":"vYoqJvxlbbLi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"79573770-6d02-4c26-b86b-2a1854a97e3a","executionInfo":{"status":"ok","timestamp":1740113870599,"user_tz":-540,"elapsed":18,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Question: 호날두로 삼행시 만들어줘\n","\n","호: 호날두는 축구장에서\n","날: 날라다니며\n","두: 두발로 골을 넣는다\n","\n"]}]},{"cell_type":"code","source":["prompt = FewShotPromptTemplate(\n","    examples=examples,\n","    example_prompt=example_prompt,\n","    suffix=\"Question: {input}\", # 사용자 입력(input)이 추가될 부분을 지정합니다. \"Question: {input}\" 형태이며, 사용자의 질문이 {input}에 들어갑니다.\n","    input_variables=[\"input\"]  # 입력 변수로 \"input\"을 사용합니다.\n",")\n","\n","print(prompt.format(input=\"손흥민으로 삼행시 만들어줘\"))"],"metadata":{"id":"Ip1L1Kvmbj6p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"67946e12-8232-4f98-f9dc-0893a8ee7f95","executionInfo":{"status":"ok","timestamp":1740114040861,"user_tz":-540,"elapsed":8,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Question: 호날두로 삼행시 만들어줘\n","\n","호: 호날두는 축구장에서\n","날: 날라다니며\n","두: 두발로 골을 넣는다\n","\n","\n","Question: 김민수로 삼행시 만들어줘\n","\n","김: 김치는 맛있다\n","민: 민달팽이도 좋아하는 김치!\n","수: 수억을 줘도 김치는 내꺼!\n","\n","\n","Question: 손흥민으로 삼행시 만들어줘\n"]}]},{"cell_type":"code","source":["print(chatgpt.invoke(\"손흥민으로 삼행시 만들어줘\")) #퓨샷 템플릿 사용을 안했을 경우"],"metadata":{"id":"ombnB2752_XU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe01bc97-81d4-4c4a-fdff-fc7d996f243a","executionInfo":{"status":"ok","timestamp":1740114059171,"user_tz":-540,"elapsed":689,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["content='손흥민은 축구 신동\\n공을 차면 상대팀 무너져\\n슈팅 강하고 빠른 발끝' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 26, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-445deb42-6853-4fc0-a396-84e193dc6564-0'\n"]}]},{"cell_type":"code","source":["answer = chatgpt([HumanMessage(content=prompt.format(input=\"손흥민으로 삼행시 만들어줘\"))])\n","print(answer.content)"],"metadata":{"id":"kOwffrVsdADU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"38fe8839-604a-4867-839e-5ea16af85143","executionInfo":{"status":"ok","timestamp":1740114066729,"user_tz":-540,"elapsed":712,"user":{"displayName":"Younghak “NorShin” Shin","userId":"13502541458389661043"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["손: 손흥민은 토트넘에서\n","흥: 흥미진진한 경기를 펼친다\n","민: 민낯으로 팬들을 사로잡는다\n"]}]}]}